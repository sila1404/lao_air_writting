# ການຮັບຮູ້ການຂຽນທາງອາກາດ ແລະ ອອກສຽງພາສາລາວໂດຍໃຊ້ວິທີການຮຽນຮູ້ແບບເລິກເຊິ່ງ

## ກ່ຽວກັບໂຄງການ

ໂຄງການນີ້ແມ່ນບົດຈົບຊັ້ນປະລິນຍາຕີ ສາຂາວິທະຍາສາດຄອມພິວເຕີ ທີ່ພັດທະນາລະບົບການຮັບຮູ້ຕົວອັກສອນລາວໂດຍໃຊ້ທ່າທາງການຂຽນດ້ວຍມືເທິງອາກາດ ແລະ ແປງຂໍ້ຄວາມທີ່ຮັບຮູ້ໄດ້ເປັນສຽງເວົ້າ. ລະບົບນີ້ໃຊ້ Computer Vision ສຳລັບການຕິດຕາມມື ແລະ ການຮັບຮູ້ທ່າທາງ, Deep Learning (CNN) ສຳລັບການຮັບຮູ້ຕົວອັກສອນ, ແລະ ເຊື່ອມຕໍ່ກັບ Text-to-Speech API ສຳລັບການອອກສຽງ.

### ຄຸນສົມບັດຫຼັກ

-   ການຕິດຕາມທ່າທາງມືແບບ Real-time ສຳລັບການຂຽນເທິງອາກາດ
-   ການຮັບຮູ້ຕົວອັກສອນລາວໂດຍໃຊ້ Convolutional Neural Networks (CNN)
-   ຮອງຮັບທັງສະຫຼະ ແລະ ພະຍັນຊະນະພາສາລາວ
-   ການແປງຂໍ້ຄວາມເປັນສຽງເວົ້າຜ່ານການເຊື່ອມຕໍ່ API
-   ໜ້າຕ່າງຕິດຕໍ່ຜູ້ໃຊ້ (GUI) ທີ່ໃຊ້ງານງ່າຍ ສ້າງດ້ວຍ Tkinter

### Demo

![Lao Air-Writing Demo](src/assets/application_demo.gif)

## ການຕິດຕັ້ງ

### ສິ່ງທີ່ຕ້ອງມີກ່ອນ

-   pixi

### ການຕິດຕັ້ງ

1.  ຕິດຕັ້ງ pixi ຖ້າທ່ານຍັງບໍ່ທັນມີ:

    -   Windows:

        ```bash
        powershell -ExecutionPolicy ByPass -c "irm -useb https://pixi.sh/install.ps1 | iex"
        ```

    -   Linux & MacOS:
        ```bash
        curl -fsSL https://pixi.sh/install.sh | sh
        ```

2.  Clone repository:

    ```bash
    git clone https://github.com/sila1404/lao_air_writting.git
    cd lao_air_writting
    ```

3.  ຕິດຕັ້ງ dependencies ໂດຍໃຊ້ pixi:
    ```bash
    pixi install
    ```

Dependencies ທີ່ຈຳເປັນທັງໝົດຖືກຈັດການໃນໄຟລ໌ `pyproject.toml`:

-   pypi dependency
    ```toml
    dependencies = [
    "certifi",
    "mediapipe>=0.10.14,<0.11",
    "tensorflow>=2.19.0,<3",
    "python-dotenv>=1.1.0,<2",
    "torch>=2.7.1,<3",
    "transformers>=4.52.4,<5",
    "accelerate>=1.7.0,<2",
    ]
    ```
-   conda dependency
    ```toml
    [tool.pixi.dependencies]
    opencv = ">=4.11.0,<5"
    numpy = "<2"
    pillow = ">=11.1.0,<12"
    seaborn = ">=0.13.2,<0.14"
    scikit-learn = ">=1.6.1,<2"
    albumentations = ">=2.0.5,<3"
    ```

## ການນຳໃຊ້

ໂຄງການປະກອບມີ 7 ຄຳສັ່ງຫຼັກສຳລັບຂັ້ນຕອນຕ່າງໆ:

### ການເກັບກຳຂໍ້ມູນ ແລະ ການເພີ່ມຂໍ້ມູນ (Data Collection and Augmentation)

-   ເກັບກຳຂໍ້ມູນ (Collect Data)

    ```bash
    pixi run collect
    ```

    -   ເປີດໜ້າຕ່າງສຳລັບການເກັບກຳຂໍ້ມູນ
    -   ໃຊ້ທ່າທາງມືເພື່ອຂຽນຕົວອັກສອນລາວ
    -   ຕົວອັກສອນຈະຖືກບັນທຶກໄວ້ໃນໂຟເດີສະຫຼະ/ພະຍັນຊະນະຕາມລຳດັບ

-   ເພີ່ມຂໍ້ມູນ (Augment Data)
    ```bash
    pixi run augment
    ```
    -   ທຳການເພີ່ມຂໍ້ມູນ (data augmentation) ໃສ່ຮູບພາບທີ່ເກັບກຳມາ
    -   ເພີ່ມຂະໜາດຂອງຊຸດຂໍ້ມູນຜ່ານການປ່ຽນແປງຮູບແບບຕ່າງໆ
    -   ຊ່ວຍປັບປຸງຄວາມທົນທານຂອງແບບຈຳລອງ

### ການເຝິກແບບຈຳລອງ (Model Training)

-   ແບ່ງຊຸດຂໍ້ມູນ (Split Dataset)

    ```bash
    pixi run split
    ```

    -   ແບ່ງຂໍ້ມູນທີ່ເກັບກຳມາອອກເປັນຊຸດຂໍ້ມູນສຳລັບເຝິກ (training) ແລະ ທົດສອບ (testing)
    -   ກຽມຂໍ້ມູນສຳລັບການເຝິກແບບຈຳລອງ

-   ເຝິກແບບຈຳລອງ (Train Model)

    ```bash
    pixi run train
    ```

    -   ເລີ່ມຕົ້ນຂະບວນການເຝິກແບບຈຳລອງ CNN
    -   ໃຊ້ຊຸດຂໍ້ມູນສຳລັບເຝິກທີ່ກຽມໄວ້
    -   ບັນທຶກແບບຈຳລອງທີ່ເຝິກສຳເລັດແລ້ວ

-   ປະເມີນແບບຈຳລອງ (Evaluate Model)

    ```bash
    pixi run eval
    ```

    -   ປະເມີນປະສິດທິພາບຂອງແບບຈຳລອງທີ່ເຝິກແລ້ວ
    -   ສ້າງຄ່າວັດແທກປະສິດທິພາບ ແລະ ລາຍງານຜົນ

-   ທົດສອບແບບຈຳລອງ (Test Model)
    ```bash
    pixi run test
    ```
    -   ເປີດໜ້າຕ່າງຫຼັກຂອງແອັບພລິເຄຊັນ
    -   ສາມາດຂຽນ ແລະ ຮັບຮູ້ຕົວອັກສອນແບບ Real-time
    -   ລວມມີຟັງຊັນການແປງຂໍ້ຄວາມເປັນສຽງເວົ້າ

### API Server

-   ເລີ່ມ API Server
    ```bash
    pixi run server
    ```
    -   ເປີດ API server ສໍາລັບການຮັບຮູ້ຕົວອັກສອນລາວ
    -   ສະຫນອງ endpoints ສໍາລັບການຮັບຮູ້ຂໍ້ຄວາມ ແລະການປ່ຽນຂໍ້ຄວາມເປັນສຽງເວົ້າ
    -   Server ເຮັດວຽກຢູ່ localhost (port ເລີ່ມຕົ້ນ: 8000)

## ການແກ້ໄຂບັນຫາ

ຖ້າທ່ານພົບບັນຫາຕໍ່ໄປນີ້:

_ModuleNotFoundError: No module named 'certifi'_

ທ່ານສາມາດແກ້ໄຂໄດ້ໂດຍການດໍາເນີນການຄໍາສັ່ງຕໍ່ໄປນີ້:

```bash
pixi clean
```

ຈາກນັ້ນ, ຕິດຕັ້ງ dependencies ຄືນໃໝ່:

```bash
pixi install
```

## ຫຼັກການເຮັດວຽກ

-   **ການຕິດຕາມມື (Hand Tracking)**: ໃຊ້ MediaPipe ສຳລັບການກວດຈັບຈຸດສຳຄັນເທິງມືແບບ Real-time
-   **ການແຕ້ມຕົວອັກສອນ (Character Drawing)**: ຕິດຕາມການເຄື່ອນໄຫວຂອງນິ້ວຊີ້ເພື່ອສ້າງຮູບແຕ້ມຕົວອັກສອນ
-   **ການຮັບຮູ້ (Recognition)**: ປະມວນຜົນຮູບແຕ້ມຜ່ານແບບຈຳລອງ CNN ທີ່ເຝິກແລ້ວ
-   **ການແປງຂໍ້ຄວາມເປັນສຽງເວົ້າ (Text-to-Speech)**: ແປງຕົວອັກສອນທີ່ຮັບຮູ້ໄດ້ເປັນສຽງເວົ້າໂດຍໃຊ້ API

## ສະຖາປັດຕະຍະກຳຂອງແບບຈຳລອງ (Model Architecture)

ແບບຈຳລອງການຮັບຮູ້ຕົວອັກສອນໃຊ້ສະຖາປັດຕະຍະກຳແບບ Convolutional Neural Network (CNN):

-   ຊັ້ນ Input ສຳລັບປະມວນຜົນຮູບພາບຕົວອັກສອນ
-   ຫຼາຍຊັ້ນ Convolutional ແລະ Pooling
-   ຊັ້ນ Dense ສຳລັບການຈັດປະເພດ
-   ຊັ້ນ Output ສຳລັບການຮັບຮູ້ຕົວອັກສອນລາວ

## ການປັບປຸງໃນອະນາຄົດ

-   ເພີ່ມຄວາມຖືກຕ້ອງໃນການຮັບຮູ້
-   ເພີ່ມການຮອງຮັບການຂຽນແບບຕໍ່ເນື່ອງ
-   ພັດທະນາການປະມວນຜົນ Text-to-Speech ແບບ Local
-   ປັບປຸງໜ້າຕ່າງຕິດຕໍ່ຜູ້ໃຊ້ (GUI)

## ຜູ້ຂຽນ

ສີລາມະນີ ໂຮມພະສະຖານ & ພົງສະຫວັນ ແສງອົກປະດິດ  
ພາກວິຊາວິທະຍາສາດຄອມພິວເຕີ  
ຄະນະວິທະຍາສາດທຳມະຊາດ
ມະຫາວິທະຍາໄລແຫ່ງຊາດລາວ

## ຂໍຂອບໃຈ

-   ອາຈານທີ່ປຶກສາ

    -   ດຣ. ສົມສັກ ອິນທະສອນ
    -   ອຈ.ປທ. ສົມມະນີ ລູຊະວົງ

-   ອາສາສະໝັກເກັບກຳຂໍ້ມູນ  
    ພວກເຮົາຂໍສະແດງຄວາມຂອບໃຈຢ່າງຈິງໃຈມາຍັງອາສາສະໝັກທຸກທ່ານທີ່ໄດ້ສະຫຼະເວລາ ແລະ ເຫື່ອແຮງໃນການສະໜອງຕົວຢ່າງລາຍມືສຳລັບຊຸດຂໍ້ມູນຂອງພວກເຮົາ:

    -   ນັກສຶກສາຈາກ ສາຂາພັດທະນາໂປຣແກຣມ, ສະຖາບັນເຕັກໂນໂລຊີ ສຸດສະກະ
    -   ສະມາຊິກຈາກ ພາກວິຊາວິທະຍາສາດຄອມພິວເຕີ

    ການປະກອບສ່ວນຂອງພວກທ່ານແມ່ນສິ່ງສຳຄັນທີ່ສຸດໃນການສ້າງຊຸດຂໍ້ມູນທີ່ຫຼາກຫຼາຍ ແລະ ຄົບຖ້ວນສຳລັບການເຝິກແບບຈຳລອງຂອງພວກເຮົາ.
